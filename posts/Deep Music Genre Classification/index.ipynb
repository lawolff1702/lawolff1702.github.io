{
 "cells": [
  {
   "cell_type": "raw",
   "id": "04c770dc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Deep Music Genre Classification\n",
    "author: Lukka Wolff\n",
    "date: '2025-05-12'\n",
    "image: \"\"\n",
    "description: \"Deep Music Genre Classification in Python\"\n",
    "categories:\n",
    "    - Natural Language Processing\n",
    "    - Neural Networks\n",
    "    - Deep Learning\n",
    "    - In Progress\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b023326",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "-- Enter Here --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94688b83",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dad640f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukka\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# for train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for suppressing bugged warnings from torchinfo\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)\n",
    "\n",
    "# tokenizers from HuggingFace\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72de72",
   "metadata": {},
   "source": [
    "We are loading in a [Kaggle dataset](https://www.kaggle.com/datasets/saurabhshahane/music-dataset-1950-to-2019) that contains information about music made between the years 1950 and 2019 collected through Spotify. The dataset contains lyrics, artist info, track names, etc. Importantly it also includes music metadata like sadness, danceability, loudness, acousticness, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f297de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/tcc_ceds_music.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c5b3e",
   "metadata": {},
   "source": [
    "Lets have a look at some of the raw data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58bdc5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>frankie laine</td>\n",
       "      <td>i believe</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>world/life</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>johnnie ray</td>\n",
       "      <td>cry</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "      <td>music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>pérez prado</td>\n",
       "      <td>patricia</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>kiss lips want stroll charm mambo chacha merin...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.744404</td>\n",
       "      <td>0.083935</td>\n",
       "      <td>0.199393</td>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>giorgos papadopoulos</td>\n",
       "      <td>apopse eida oneiro</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>till darling till matter know till dream live ...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.291671</td>\n",
       "      <td>0.646489</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.597073</td>\n",
       "      <td>0.394375</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           artist_name            track_name  release_date genre  \\\n",
       "0           0                mukesh  mohabbat bhi jhoothi          1950   pop   \n",
       "1           4         frankie laine             i believe          1950   pop   \n",
       "2           6           johnnie ray                   cry          1950   pop   \n",
       "3          10           pérez prado              patricia          1950   pop   \n",
       "4          12  giorgos papadopoulos    apopse eida oneiro          1950   pop   \n",
       "\n",
       "                                              lyrics  len    dating  violence  \\\n",
       "0  hold time feel break feel untrue convince spea...   95  0.000598  0.063746   \n",
       "1  believe drop rain fall grow believe darkest ni...   51  0.035537  0.096777   \n",
       "2  sweetheart send letter goodbye secret feel bet...   24  0.002770  0.002770   \n",
       "3  kiss lips want stroll charm mambo chacha merin...   54  0.048249  0.001548   \n",
       "4  till darling till matter know till dream live ...   48  0.001350  0.001350   \n",
       "\n",
       "   world/life  ...   sadness  feelings  danceability  loudness  acousticness  \\\n",
       "0    0.000598  ...  0.380299  0.117175      0.357739  0.454119      0.997992   \n",
       "1    0.443435  ...  0.001284  0.001284      0.331745  0.647540      0.954819   \n",
       "2    0.002770  ...  0.002770  0.225422      0.456298  0.585288      0.840361   \n",
       "3    0.001548  ...  0.225889  0.001548      0.686992  0.744404      0.083935   \n",
       "4    0.417772  ...  0.068800  0.001350      0.291671  0.646489      0.975904   \n",
       "\n",
       "   instrumentalness   valence    energy       topic  age  \n",
       "0          0.901822  0.339448  0.137110     sadness  1.0  \n",
       "1          0.000002  0.325021  0.263240  world/life  1.0  \n",
       "2          0.000000  0.351814  0.139112       music  1.0  \n",
       "3          0.199393  0.775350  0.743736    romantic  1.0  \n",
       "4          0.000246  0.597073  0.394375    romantic  1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c455d",
   "metadata": {},
   "source": [
    "Here is a brief look at how many songs we have in each represented genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2300648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "blues      4604\n",
       "country    5445\n",
       "hip hop     904\n",
       "jazz       3845\n",
       "pop        7042\n",
       "reggae     2498\n",
       "rock       4034\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"genre\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f7dcaf",
   "metadata": {},
   "source": [
    "This is a pretty large number of songs to classify... and some genres I personally dont care for. So, to make the dataframe more manageable and applicable to me personally, we are going to narrow down to only observe reggae, hip hop, rock and jazz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaaf27ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17091</th>\n",
       "      <td>54304</td>\n",
       "      <td>gene ammons</td>\n",
       "      <td>it's the talk of the town</td>\n",
       "      <td>1950</td>\n",
       "      <td>jazz</td>\n",
       "      <td>lovers sweethearts hard understand know happen...</td>\n",
       "      <td>61</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319570</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.352323</td>\n",
       "      <td>0.620388</td>\n",
       "      <td>0.868474</td>\n",
       "      <td>0.235830</td>\n",
       "      <td>0.430132</td>\n",
       "      <td>0.282260</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17092</th>\n",
       "      <td>54305</td>\n",
       "      <td>gene ammons</td>\n",
       "      <td>you go to my head</td>\n",
       "      <td>1950</td>\n",
       "      <td>jazz</td>\n",
       "      <td>head linger like haunt refrain spin round brai...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.340964</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>0.638541</td>\n",
       "      <td>0.907630</td>\n",
       "      <td>0.900810</td>\n",
       "      <td>0.221970</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>violence</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17093</th>\n",
       "      <td>54307</td>\n",
       "      <td>bud powell</td>\n",
       "      <td>yesterdays</td>\n",
       "      <td>1950</td>\n",
       "      <td>jazz</td>\n",
       "      <td>music speak start hear musicians like dizzy gi...</td>\n",
       "      <td>107</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.074762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.097082</td>\n",
       "      <td>0.489873</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.992972</td>\n",
       "      <td>0.927126</td>\n",
       "      <td>0.334295</td>\n",
       "      <td>0.228204</td>\n",
       "      <td>music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17094</th>\n",
       "      <td>54311</td>\n",
       "      <td>tony bennett</td>\n",
       "      <td>stranger in paradise</td>\n",
       "      <td>1950</td>\n",
       "      <td>jazz</td>\n",
       "      <td>hand stranger paradise lose wonderland strange...</td>\n",
       "      <td>41</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.180524</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527429</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.179032</td>\n",
       "      <td>0.559470</td>\n",
       "      <td>0.983936</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.086974</td>\n",
       "      <td>0.235211</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17095</th>\n",
       "      <td>54313</td>\n",
       "      <td>dean martin</td>\n",
       "      <td>zing-a zing-a zing boom</td>\n",
       "      <td>1950</td>\n",
       "      <td>jazz</td>\n",
       "      <td>zinga zinga zinga zinga zinga zinga zinga zing...</td>\n",
       "      <td>160</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425721</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.580851</td>\n",
       "      <td>0.687409</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   artist_name                 track_name  release_date  \\\n",
       "17091       54304   gene ammons  it's the talk of the town          1950   \n",
       "17092       54305   gene ammons          you go to my head          1950   \n",
       "17093       54307    bud powell                 yesterdays          1950   \n",
       "17094       54311  tony bennett       stranger in paradise          1950   \n",
       "17095       54313   dean martin    zing-a zing-a zing boom          1950   \n",
       "\n",
       "      genre                                             lyrics  len    dating  \\\n",
       "17091  jazz  lovers sweethearts hard understand know happen...   61  0.001096   \n",
       "17092  jazz  head linger like haunt refrain spin round brai...   48  0.001754   \n",
       "17093  jazz  music speak start hear musicians like dizzy gi...  107  0.001144   \n",
       "17094  jazz  hand stranger paradise lose wonderland strange...   41  0.002105   \n",
       "17095  jazz  zinga zinga zinga zinga zinga zinga zinga zing...  160  0.001253   \n",
       "\n",
       "       violence  world/life  ...   sadness  feelings  danceability  loudness  \\\n",
       "17091  0.001096    0.001096  ...  0.319570  0.001096      0.352323  0.620388   \n",
       "17092  0.340964    0.001754  ...  0.001754  0.001754      0.379400  0.638541   \n",
       "17093  0.001144    0.074762  ...  0.001144  0.097082      0.489873  0.467400   \n",
       "17094  0.180524    0.002105  ...  0.527429  0.002105      0.179032  0.559470   \n",
       "17095  0.001253    0.001253  ...  0.425721  0.001253      0.580851  0.687409   \n",
       "\n",
       "       acousticness  instrumentalness   valence    energy     topic  age  \n",
       "17091      0.868474          0.235830  0.430132  0.282260   sadness  1.0  \n",
       "17092      0.907630          0.900810  0.221970  0.184159  violence  1.0  \n",
       "17093      0.992972          0.927126  0.334295  0.228204     music  1.0  \n",
       "17094      0.983936          0.001781  0.086974  0.235211   sadness  1.0  \n",
       "17095      0.655622          0.000000  0.936109  0.418400   sadness  1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = {\n",
    "    \"hip hop\"   : 0,\n",
    "    \"jazz\" : 1,\n",
    "    \"reggae\" : 2,\n",
    "    \"rock\" : 3,\n",
    "}\n",
    "\n",
    "df = df[df[\"genre\"].apply(lambda x: x in genres.keys())]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf486021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17091</th>\n",
       "      <td>54304</td>\n",
       "      <td>gene ammons</td>\n",
       "      <td>it's the talk of the town</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>lovers sweethearts hard understand know happen...</td>\n",
       "      <td>61</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319570</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.352323</td>\n",
       "      <td>0.620388</td>\n",
       "      <td>0.868474</td>\n",
       "      <td>0.235830</td>\n",
       "      <td>0.430132</td>\n",
       "      <td>0.282260</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17092</th>\n",
       "      <td>54305</td>\n",
       "      <td>gene ammons</td>\n",
       "      <td>you go to my head</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>head linger like haunt refrain spin round brai...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.340964</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>0.638541</td>\n",
       "      <td>0.907630</td>\n",
       "      <td>0.900810</td>\n",
       "      <td>0.221970</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>violence</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17093</th>\n",
       "      <td>54307</td>\n",
       "      <td>bud powell</td>\n",
       "      <td>yesterdays</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>music speak start hear musicians like dizzy gi...</td>\n",
       "      <td>107</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.074762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.097082</td>\n",
       "      <td>0.489873</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.992972</td>\n",
       "      <td>0.927126</td>\n",
       "      <td>0.334295</td>\n",
       "      <td>0.228204</td>\n",
       "      <td>music</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17094</th>\n",
       "      <td>54311</td>\n",
       "      <td>tony bennett</td>\n",
       "      <td>stranger in paradise</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>hand stranger paradise lose wonderland strange...</td>\n",
       "      <td>41</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.180524</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527429</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.179032</td>\n",
       "      <td>0.559470</td>\n",
       "      <td>0.983936</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.086974</td>\n",
       "      <td>0.235211</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17095</th>\n",
       "      <td>54313</td>\n",
       "      <td>dean martin</td>\n",
       "      <td>zing-a zing-a zing boom</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>zinga zinga zinga zinga zinga zinga zinga zing...</td>\n",
       "      <td>160</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425721</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.580851</td>\n",
       "      <td>0.687409</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28367</th>\n",
       "      <td>82447</td>\n",
       "      <td>mack 10</td>\n",
       "      <td>10 million ways</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>cause fuck leave scar tick tock clock come kno...</td>\n",
       "      <td>78</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065664</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.889527</td>\n",
       "      <td>0.759711</td>\n",
       "      <td>0.062549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751649</td>\n",
       "      <td>0.695686</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28368</th>\n",
       "      <td>82448</td>\n",
       "      <td>m.o.p.</td>\n",
       "      <td>ante up (robbin hoodz theory)</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>minks things chain ring braclets yap fame come...</td>\n",
       "      <td>67</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.035338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.789580</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.922712</td>\n",
       "      <td>0.797791</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28369</th>\n",
       "      <td>82449</td>\n",
       "      <td>nine</td>\n",
       "      <td>whutcha want?</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>get ban get ban stick crack relax plan attack ...</td>\n",
       "      <td>77</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.154302</td>\n",
       "      <td>0.168988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.663165</td>\n",
       "      <td>0.726970</td>\n",
       "      <td>0.104417</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.838211</td>\n",
       "      <td>0.767761</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28370</th>\n",
       "      <td>82450</td>\n",
       "      <td>will smith</td>\n",
       "      <td>switch</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>check check yeah yeah hear thing call switch g...</td>\n",
       "      <td>67</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.883028</td>\n",
       "      <td>0.786888</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.508450</td>\n",
       "      <td>0.885882</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28371</th>\n",
       "      <td>82451</td>\n",
       "      <td>jeezy</td>\n",
       "      <td>r.i.p.</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>remix killer alive remix thriller trap bitch s...</td>\n",
       "      <td>83</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>0.828875</td>\n",
       "      <td>0.674794</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475474</td>\n",
       "      <td>0.492477</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11281 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   artist_name                     track_name  release_date  \\\n",
       "17091       54304   gene ammons      it's the talk of the town          1950   \n",
       "17092       54305   gene ammons              you go to my head          1950   \n",
       "17093       54307    bud powell                     yesterdays          1950   \n",
       "17094       54311  tony bennett           stranger in paradise          1950   \n",
       "17095       54313   dean martin        zing-a zing-a zing boom          1950   \n",
       "...           ...           ...                            ...           ...   \n",
       "28367       82447       mack 10                10 million ways          2019   \n",
       "28368       82448        m.o.p.  ante up (robbin hoodz theory)          2019   \n",
       "28369       82449          nine                  whutcha want?          2019   \n",
       "28370       82450    will smith                         switch          2019   \n",
       "28371       82451         jeezy                         r.i.p.          2019   \n",
       "\n",
       "       genre                                             lyrics  len  \\\n",
       "17091      1  lovers sweethearts hard understand know happen...   61   \n",
       "17092      1  head linger like haunt refrain spin round brai...   48   \n",
       "17093      1  music speak start hear musicians like dizzy gi...  107   \n",
       "17094      1  hand stranger paradise lose wonderland strange...   41   \n",
       "17095      1  zinga zinga zinga zinga zinga zinga zinga zing...  160   \n",
       "...      ...                                                ...  ...   \n",
       "28367      0  cause fuck leave scar tick tock clock come kno...   78   \n",
       "28368      0  minks things chain ring braclets yap fame come...   67   \n",
       "28369      0  get ban get ban stick crack relax plan attack ...   77   \n",
       "28370      0  check check yeah yeah hear thing call switch g...   67   \n",
       "28371      0  remix killer alive remix thriller trap bitch s...   83   \n",
       "\n",
       "         dating  violence  world/life  ...   sadness  feelings  danceability  \\\n",
       "17091  0.001096  0.001096    0.001096  ...  0.319570  0.001096      0.352323   \n",
       "17092  0.001754  0.340964    0.001754  ...  0.001754  0.001754      0.379400   \n",
       "17093  0.001144  0.001144    0.074762  ...  0.001144  0.097082      0.489873   \n",
       "17094  0.002105  0.180524    0.002105  ...  0.527429  0.002105      0.179032   \n",
       "17095  0.001253  0.001253    0.001253  ...  0.425721  0.001253      0.580851   \n",
       "...         ...       ...         ...  ...       ...       ...           ...   \n",
       "28367  0.001350  0.001350    0.001350  ...  0.065664  0.001350      0.889527   \n",
       "28368  0.001284  0.001284    0.035338  ...  0.001284  0.001284      0.662082   \n",
       "28369  0.001504  0.154302    0.168988  ...  0.001504  0.001504      0.663165   \n",
       "28370  0.001196  0.001196    0.001196  ...  0.001196  0.001196      0.883028   \n",
       "28371  0.001012  0.075202    0.001012  ...  0.001012  0.033995      0.828875   \n",
       "\n",
       "       loudness  acousticness  instrumentalness   valence    energy     topic  \\\n",
       "17091  0.620388      0.868474          0.235830  0.430132  0.282260   sadness   \n",
       "17092  0.638541      0.907630          0.900810  0.221970  0.184159  violence   \n",
       "17093  0.467400      0.992972          0.927126  0.334295  0.228204     music   \n",
       "17094  0.559470      0.983936          0.001781  0.086974  0.235211   sadness   \n",
       "17095  0.687409      0.655622          0.000000  0.936109  0.418400   sadness   \n",
       "...         ...           ...               ...       ...       ...       ...   \n",
       "28367  0.759711      0.062549          0.000000  0.751649  0.695686   obscene   \n",
       "28368  0.789580      0.004607          0.000002  0.922712  0.797791   obscene   \n",
       "28369  0.726970      0.104417          0.000001  0.838211  0.767761   obscene   \n",
       "28370  0.786888      0.007027          0.000503  0.508450  0.885882   obscene   \n",
       "28371  0.674794      0.015862          0.000000  0.475474  0.492477   obscene   \n",
       "\n",
       "            age  \n",
       "17091  1.000000  \n",
       "17092  1.000000  \n",
       "17093  1.000000  \n",
       "17094  1.000000  \n",
       "17095  1.000000  \n",
       "...         ...  \n",
       "28367  0.014286  \n",
       "28368  0.014286  \n",
       "28369  0.014286  \n",
       "28370  0.014286  \n",
       "28371  0.014286  \n",
       "\n",
       "[11281 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"genre\"] = df[\"genre\"].apply(genres.get)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08060709",
   "metadata": {},
   "source": [
    "The base rate on our classification is the proportion of the data set occupied by the largest label class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7065f720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "0    0.080135\n",
       "1    0.340839\n",
       "2    0.221434\n",
       "3    0.357592\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"genre\").size() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd47316",
   "metadata": {},
   "source": [
    "If we always guessed category 3, then we would expect an accuracy of **roughly 36%**. So, our task will be to see whether we can train a model to beat this. \n",
    "\n",
    "As we try to predict the genre of the track, we will use lyrics alongside some other engineered features (metadata) that we define below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bccea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features = ['dating', 'violence', 'world/life', 'night/time','shake the audience','family/gospel', 'romantic', 'communication','obscene', 'music', 'movement/places', 'light/visual perceptions','family/spiritual', 'like/girls', 'sadness', 'feelings', 'danceability','loudness', 'acousticness', 'instrumentalness', 'valence', 'energy']      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78aed25",
   "metadata": {},
   "source": [
    "Our models will only need these engineered features, lyrics, and our target value which will be *genre* so we can throw them all into the same dataframe and use slicing to access different parts later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e570cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>night/time</th>\n",
       "      <th>shake the audience</th>\n",
       "      <th>family/gospel</th>\n",
       "      <th>romantic</th>\n",
       "      <th>communication</th>\n",
       "      <th>obscene</th>\n",
       "      <th>music</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17091</th>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.036316</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.460773</td>\n",
       "      <td>0.086498</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319570</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.352323</td>\n",
       "      <td>0.620388</td>\n",
       "      <td>0.868474</td>\n",
       "      <td>0.235830</td>\n",
       "      <td>0.430132</td>\n",
       "      <td>0.282260</td>\n",
       "      <td>lovers sweethearts hard understand know happen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17092</th>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.340964</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.131872</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>0.638541</td>\n",
       "      <td>0.907630</td>\n",
       "      <td>0.900810</td>\n",
       "      <td>0.221970</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>head linger like haunt refrain spin round brai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17093</th>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.074762</td>\n",
       "      <td>0.046173</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.018789</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.421734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.097082</td>\n",
       "      <td>0.489873</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.992972</td>\n",
       "      <td>0.927126</td>\n",
       "      <td>0.334295</td>\n",
       "      <td>0.228204</td>\n",
       "      <td>music speak start hear musicians like dizzy gi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17094</th>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.180524</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.201965</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527429</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.179032</td>\n",
       "      <td>0.559470</td>\n",
       "      <td>0.983936</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.086974</td>\n",
       "      <td>0.235211</td>\n",
       "      <td>hand stranger paradise lose wonderland strange...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17095</th>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.081126</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.111951</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.268737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425721</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.580851</td>\n",
       "      <td>0.687409</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>zinga zinga zinga zinga zinga zinga zinga zing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dating  violence  world/life  night/time  shake the audience  \\\n",
       "17091  0.001096  0.001096    0.001096    0.001096            0.036316   \n",
       "17092  0.001754  0.340964    0.001754    0.001754            0.001754   \n",
       "17093  0.001144  0.001144    0.074762    0.046173            0.001144   \n",
       "17094  0.002105  0.180524    0.002105    0.002105            0.002105   \n",
       "17095  0.001253  0.001253    0.001253    0.001253            0.001253   \n",
       "\n",
       "       family/gospel  romantic  communication   obscene     music  ...  \\\n",
       "17091       0.001096  0.001096       0.460773  0.086498  0.001096  ...   \n",
       "17092       0.001754  0.131872       0.001754  0.001754  0.001754  ...   \n",
       "17093       0.018789  0.001144       0.001655  0.001144  0.421734  ...   \n",
       "17094       0.002105  0.002105       0.201965  0.002105  0.002105  ...   \n",
       "17095       0.081126  0.001253       0.111951  0.001253  0.268737  ...   \n",
       "\n",
       "        sadness  feelings  danceability  loudness  acousticness  \\\n",
       "17091  0.319570  0.001096      0.352323  0.620388      0.868474   \n",
       "17092  0.001754  0.001754      0.379400  0.638541      0.907630   \n",
       "17093  0.001144  0.097082      0.489873  0.467400      0.992972   \n",
       "17094  0.527429  0.002105      0.179032  0.559470      0.983936   \n",
       "17095  0.425721  0.001253      0.580851  0.687409      0.655622   \n",
       "\n",
       "       instrumentalness   valence    energy  \\\n",
       "17091          0.235830  0.430132  0.282260   \n",
       "17092          0.900810  0.221970  0.184159   \n",
       "17093          0.927126  0.334295  0.228204   \n",
       "17094          0.001781  0.086974  0.235211   \n",
       "17095          0.000000  0.936109  0.418400   \n",
       "\n",
       "                                                  lyrics  genre  \n",
       "17091  lovers sweethearts hard understand know happen...      1  \n",
       "17092  head linger like haunt refrain spin round brai...      1  \n",
       "17093  music speak start hear musicians like dizzy gi...      1  \n",
       "17094  hand stranger paradise lose wonderland strange...      1  \n",
       "17095  zinga zinga zinga zinga zinga zinga zinga zing...      1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean= df[engineered_features + ['lyrics', 'genre']].copy()\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdb0d67",
   "metadata": {},
   "source": [
    "Finally, we will perform a train-validation split to later evaluate our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d16bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_clean,shuffle = True, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731b78b",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7172d9",
   "metadata": {},
   "source": [
    "We now need to *vectorize* the lyrics. We’re going to use **tokenization** to break up the lyrics into a sequence of tokens, and then vectorize that sequence.\n",
    "\n",
    "We will be using a tokenizer imported from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df0d265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c770c",
   "metadata": {},
   "source": [
    "For our purposes it’s more convenient to assign an *integer* to each token, which we can do like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a11810f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 15662, 2189, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tokenizer(\"I love reggae music!\")\n",
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbfa921",
   "metadata": {},
   "source": [
    "To do the reverse, we can use the `.decode` method of the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e21097f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] i love reggae music! [SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e26c5",
   "metadata": {},
   "source": [
    "Here is some code to help us prepare our dataset with encodings. A lot of our lyrics are different lengths so we will pad the shorter ones with 0s and truncate others that are especially long. We will make use of the torch `Dataset` class to help manage our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "067e73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512 # BERT capacity\n",
    "\n",
    "def preprocess(df, tokenizer, max_len):\n",
    "    lyrics_tokens = tokenizer(list(df[\"lyrics\"]), padding=\"max_length\", truncation=True, max_length=max_len)[\"input_ids\"]\n",
    "    engineered = df[engineered_features].values.tolist()\n",
    "    y = list(df[\"genre\"])\n",
    "    return lyrics_tokens, engineered, y\n",
    "\n",
    "class TextDataFromDF(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.lyrics_tokens, self.engineered_feats, self.y = preprocess(df, tokenizer, max_len)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.lyrics_tokens[ix], self.engineered_feats[ix], self.y[ix]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb98b2",
   "metadata": {},
   "source": [
    "Lets make our encoded datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09224851",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TextDataFromDF(df_train)\n",
    "val_data   = TextDataFromDF(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7df72",
   "metadata": {},
   "source": [
    "Here is what a single songs information looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff257b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 3328, 2907, 2132, 2152, 4452, 2601, 3585, 4086, 3165, 2299, 3328, 3612, 3328, 4542, 3959, 10055, 6271, 3328, 3328, 2540, 3328, 3328, 3328, 2907, 2132, 2152, 4452, 2601, 3585, 4086, 3165, 2299, 3328, 3612, 3328, 4542, 3959, 10055, 6271, 3328, 3328, 2540, 3328, 3328, 3328, 3328, 2540, 3328, 3328, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0.0010964912324282, 0.0010964912976541, 0.0010964912384155, 0.0010964912293336, 0.0010964912288606, 0.0010964912280702, 0.0710460412436734, 0.0010964912450082, 0.00109649124238, 0.06725964640425, 0.0010964912776641, 0.3439465725728195, 0.0010964912312102, 0.0010964912435438, 0.5013003710524483, 0.0010964912281679, 0.2895050362828983, 0.6547445068328077, 0.4367464224361671, 2.2165991902834004e-05, 0.2755564715581204, 0.3703507056476638]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "X_tokens, X_feats, y = train_data[1]\n",
    "print(X_tokens, X_feats)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e2e76",
   "metadata": {},
   "source": [
    "We are going to be feeding data in in batches, so we will need a dataloader which necessitates a collate function to ensure our we are imputing tensors of the right size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a751a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(data):\n",
    "    tokens = torch.tensor([d[0] for d in data], dtype=torch.long)\n",
    "    engineered = torch.tensor([d[1] for d in data], dtype=torch.float)\n",
    "    y = torch.tensor([d[2] for d in data], dtype=torch.long)\n",
    "    return (tokens, engineered), y\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, collate_fn = collate)\n",
    "val_loader = DataLoader(val_data, batch_size=8, shuffle=True, collate_fn = collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cb3a6e",
   "metadata": {},
   "source": [
    "Here is what a batch of data looks like. The predictor data is now a tensor in which the entries give token indices, padded with 0s and another tensor with the  values of our engineered features. For visualization purposes we’ll show only the first 2 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b18de88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 4101, 2614,  ...,    0,    0,    0],\n",
       "         [ 101, 3441, 2425,  ...,    0,    0,    0],\n",
       "         [ 101, 2293, 6171,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 4542, 2228,  ...,    0,    0,    0],\n",
       "         [ 101, 2300, 2307,  ...,    0,    0,    0],\n",
       "         [ 101, 3336, 2088,  ...,    0,    0,    0]]),\n",
       " tensor([[5.8480e-03, 5.8480e-03, 5.8480e-03, 5.8480e-03, 9.2967e-02, 5.8480e-03,\n",
       "          5.8480e-03, 5.8480e-03, 5.6022e-01, 2.5324e-01, 5.8480e-03, 5.8480e-03,\n",
       "          5.8480e-03, 5.8480e-03, 5.8480e-03, 5.8480e-03, 5.5919e-01, 6.8002e-01,\n",
       "          4.1064e-01, 9.0283e-01, 7.5577e-01, 6.3863e-01],\n",
       "         [6.1200e-04, 6.1200e-04, 3.2425e-01, 1.6469e-01, 6.1200e-04, 6.1200e-04,\n",
       "          6.1200e-04, 3.7032e-01, 6.1200e-04, 6.1200e-04, 3.4029e-02, 6.1200e-04,\n",
       "          6.1200e-04, 6.1200e-04, 8.5875e-02, 6.1200e-04, 5.9818e-01, 6.7177e-01,\n",
       "          2.5201e-01, 4.2409e-02, 3.5697e-01, 5.4553e-01],\n",
       "         [4.3860e-03, 1.9015e-01, 4.3860e-03, 4.3860e-03, 4.3860e-03, 4.3860e-03,\n",
       "          4.0664e-01, 4.3860e-03, 4.3860e-03, 2.1453e-01, 4.3860e-03, 4.3860e-03,\n",
       "          1.2289e-01, 4.3860e-03, 4.3860e-03, 4.3860e-03, 4.0973e-01, 6.1988e-01,\n",
       "          9.5783e-01, 9.7672e-05, 9.4188e-02, 1.8516e-01],\n",
       "         [1.2837e-03, 1.2437e-01, 5.4941e-01, 1.0511e-01, 1.2837e-03, 1.2837e-03,\n",
       "          1.2837e-03, 1.2837e-03, 1.2837e-03, 1.2837e-03, 1.2837e-03, 1.2837e-03,\n",
       "          1.2837e-03, 1.2837e-03, 1.3983e-01, 2.4200e-02, 6.0685e-01, 6.6156e-01,\n",
       "          1.7169e-01, 1.4575e-03, 2.8895e-01, 5.2551e-01],\n",
       "         [1.8674e-01, 2.4353e-01, 1.4225e-03, 1.4225e-03, 6.4501e-02, 1.4225e-03,\n",
       "          9.2653e-02, 1.4225e-03, 1.4225e-03, 1.4225e-03, 1.4225e-03, 1.4225e-03,\n",
       "          1.4225e-03, 1.4225e-03, 3.9267e-01, 1.4225e-03, 6.9024e-01, 3.4205e-01,\n",
       "          9.8092e-01, 9.4838e-01, 6.6509e-01, 8.7259e-02],\n",
       "         [7.5188e-04, 6.6508e-02, 1.1153e-01, 7.5188e-04, 7.5188e-04, 1.7943e-02,\n",
       "          7.5188e-04, 2.0908e-01, 7.5188e-04, 7.5188e-04, 7.5188e-04, 7.5188e-04,\n",
       "          7.5188e-04, 7.0969e-02, 3.1324e-01, 7.5188e-04, 5.2345e-01, 5.0791e-01,\n",
       "          5.2299e-03, 5.2227e-03, 7.3825e-01, 3.1830e-01],\n",
       "         [1.1198e-03, 5.2728e-01, 1.1198e-03, 1.1198e-03, 1.1198e-03, 1.1198e-03,\n",
       "          1.1198e-03, 1.1198e-03, 1.1198e-03, 1.1198e-03, 1.1198e-03, 1.1198e-03,\n",
       "          1.1770e-01, 1.1198e-03, 6.7696e-02, 1.1198e-03, 6.2742e-01, 7.0423e-01,\n",
       "          3.7751e-01, 1.2348e-04, 4.6311e-01, 6.4063e-01],\n",
       "         [1.4427e-01, 1.3495e-03, 3.0550e-01, 1.3495e-03, 1.3495e-03, 1.6269e-01,\n",
       "          1.3495e-03, 1.3495e-03, 1.3495e-03, 3.5433e-02, 1.3495e-03, 1.4791e-01,\n",
       "          1.3495e-03, 1.3495e-03, 1.5215e-01, 1.3495e-03, 5.7869e-01, 3.6984e-01,\n",
       "          9.3173e-01, 3.1883e-01, 9.0066e-02, 1.3211e-01]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13b5056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2550573",
   "metadata": {},
   "source": [
    "# Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f5663f",
   "metadata": {},
   "source": [
    "We are going to train **three** neural networks to classify our genres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b18f5e7",
   "metadata": {},
   "source": [
    "- Using Lyrics to Classify\n",
    "- Using Engineered Features (Metadata) to Classify\n",
    "- Using Lyrics and Metadata to Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dffc3d",
   "metadata": {},
   "source": [
    "Lets build a model for classifying genres based on lyrics first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1eb253",
   "metadata": {},
   "source": [
    "## Lyrical Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aba4f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size, embedding_dim, max_len, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size+1, embedding_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(embedding_dim, num_class) # max_len*embedding_dim\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.mean(axis = 1)\n",
    "        # x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb0291",
   "metadata": {},
   "source": [
    "Our model begins with the embedding layer where each word is looked up in an embedding table and turned into a learned vector of size `embedding_dim`. We then pass the embedding into a dropout layer where 20% of the embedding vectors are randomly zeroed. This is a form of regularization step meant to help us not be over-reliant on certain tokens. Our mean-pool layer reduces our dimension by averaging all token embeddings so each song is now a fixed-size vector. Finally, our linear layer gives us our probabilities for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec0d5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.vocab)\n",
    "embedding_dim = 25\n",
    "num_class = len(genres)\n",
    "\n",
    "text_model = TextClassificationModel(vocab_size, embedding_dim, max_len, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30b7a935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "TextClassificationModel                  --\n",
       "├─Embedding: 1-1                         763,075\n",
       "├─Dropout: 1-2                           --\n",
       "├─Linear: 1-3                            104\n",
       "├─ReLU: 1-4                              --\n",
       "=================================================================\n",
       "Total params: 763,179\n",
       "Trainable params: 763,179\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(text_model, input_Size = (8, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cda0fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, mode=\"lyrics\"):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "    # keep track of some counts for measuring accuracy\n",
    "    total_acc, total_count = 0, 0\n",
    "    \n",
    "    for X, y in dataloader:\n",
    "        # unpack and move to device\n",
    "        tokens, engineered = X\n",
    "        y = y.to(device)\n",
    "\n",
    "        if mode == \"lyrics\":\n",
    "            data = tokens.to(device)\n",
    "        elif mode == \"engineered\":\n",
    "            data = engineered.to(device)\n",
    "        else:\n",
    "            data = X\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # form prediction on batch\n",
    "        predicted_label = model(data)\n",
    "        # evaluate loss on prediction\n",
    "        loss = loss_fn(predicted_label, y)\n",
    "        # compute gradient\n",
    "        loss.backward()\n",
    "        # take an optimization step\n",
    "        optimizer.step()\n",
    "                \n",
    "        # for printing accuracy\n",
    "        total_acc += (predicted_label.argmax(1) == y).sum().item()\n",
    "        total_count += y.size(0)\n",
    "\n",
    "    print(f'| epoch {epoch:3d} | train accuracy {total_acc/total_count:8.3f} | time: {time.time() - epoch_start_time:5.2f}s')\n",
    "\n",
    "def accuracy(model, dataloader, mode=\"lyrics\"):\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # unpack and move to device\n",
    "            tokens, engineered = X\n",
    "            y = y.to(device)\n",
    "\n",
    "            if mode == \"lyrics\":\n",
    "                data = tokens.to(device)\n",
    "            elif mode == \"engineered\":\n",
    "                data = engineered.to(device)\n",
    "            elif mode == \"both\":\n",
    "                data = X\n",
    "\n",
    "            predicted_label = model(data)\n",
    "            total_acc += (predicted_label.argmax(1) == y).sum().item()\n",
    "            total_count += y.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5303ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | train accuracy    0.372 | time:  4.24s\n",
      "| epoch   2 | train accuracy    0.387 | time:  4.41s\n",
      "| epoch   3 | train accuracy    0.398 | time:  4.32s\n",
      "| epoch   4 | train accuracy    0.401 | time:  4.18s\n",
      "| epoch   5 | train accuracy    0.405 | time:  4.29s\n",
      "| epoch   6 | train accuracy    0.414 | time:  4.44s\n",
      "| epoch   7 | train accuracy    0.421 | time:  4.47s\n",
      "| epoch   8 | train accuracy    0.436 | time:  4.39s\n",
      "| epoch   9 | train accuracy    0.439 | time:  4.24s\n",
      "| epoch  10 | train accuracy    0.454 | time:  4.53s\n",
      "| epoch  11 | train accuracy    0.467 | time:  4.73s\n",
      "| epoch  12 | train accuracy    0.478 | time:  4.51s\n",
      "| epoch  13 | train accuracy    0.492 | time:  4.54s\n",
      "| epoch  14 | train accuracy    0.499 | time:  4.32s\n",
      "| epoch  15 | train accuracy    0.517 | time:  4.40s\n",
      "| epoch  16 | train accuracy    0.527 | time:  4.43s\n",
      "| epoch  17 | train accuracy    0.546 | time:  4.27s\n",
      "| epoch  18 | train accuracy    0.557 | time:  4.38s\n",
      "| epoch  19 | train accuracy    0.567 | time:  4.41s\n",
      "| epoch  20 | train accuracy    0.576 | time:  4.47s\n",
      "| epoch  21 | train accuracy    0.588 | time:  4.51s\n",
      "| epoch  22 | train accuracy    0.597 | time:  4.36s\n",
      "| epoch  23 | train accuracy    0.610 | time:  4.42s\n",
      "| epoch  24 | train accuracy    0.619 | time:  4.40s\n",
      "| epoch  25 | train accuracy    0.629 | time:  4.24s\n",
      "| epoch  26 | train accuracy    0.637 | time:  4.25s\n",
      "| epoch  27 | train accuracy    0.643 | time:  4.19s\n",
      "| epoch  28 | train accuracy    0.649 | time:  4.34s\n",
      "| epoch  29 | train accuracy    0.660 | time:  4.56s\n",
      "| epoch  30 | train accuracy    0.664 | time:  4.17s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(text_model, train_loader, \"lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e236043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5604785112981834"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(text_model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b6cc38",
   "metadata": {},
   "source": [
    "## Engineered Features Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c49c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_class):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.pipeline = nn.Sequential(\n",
    "            nn.Linear(num_features, 18), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 12), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 8), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, num_class)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipeline(x)\n",
    "\n",
    "    def predict(self, x): \n",
    "        return self.score(x) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92120b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MetadataClassificationModel              --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Linear: 2-1                       414\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Linear: 2-3                       228\n",
       "│    └─ReLU: 2-4                         --\n",
       "│    └─Linear: 2-5                       104\n",
       "│    └─ReLU: 2-6                         --\n",
       "│    └─Linear: 2-7                       36\n",
       "=================================================================\n",
       "Total params: 782\n",
       "Trainable params: 782\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = len(engineered_features)\n",
    "\n",
    "meta_model = MetadataClassificationModel(num_features, num_class).to(device)\n",
    "summary(meta_model, input_Size = (8, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f986713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | train accuracy    0.517 | time:  4.36s\n",
      "| epoch   2 | train accuracy    0.613 | time:  4.32s\n",
      "| epoch   3 | train accuracy    0.626 | time:  4.22s\n",
      "| epoch   4 | train accuracy    0.631 | time:  4.11s\n",
      "| epoch   5 | train accuracy    0.634 | time:  4.17s\n",
      "| epoch   6 | train accuracy    0.636 | time:  4.46s\n",
      "| epoch   7 | train accuracy    0.639 | time:  4.35s\n",
      "| epoch   8 | train accuracy    0.638 | time:  4.23s\n",
      "| epoch   9 | train accuracy    0.642 | time:  4.40s\n",
      "| epoch  10 | train accuracy    0.640 | time:  3.97s\n",
      "| epoch  11 | train accuracy    0.639 | time:  3.61s\n",
      "| epoch  12 | train accuracy    0.641 | time:  3.81s\n",
      "| epoch  13 | train accuracy    0.646 | time:  3.63s\n",
      "| epoch  14 | train accuracy    0.644 | time:  3.85s\n",
      "| epoch  15 | train accuracy    0.647 | time:  4.24s\n",
      "| epoch  16 | train accuracy    0.651 | time:  3.83s\n",
      "| epoch  17 | train accuracy    0.654 | time:  3.82s\n",
      "| epoch  18 | train accuracy    0.656 | time:  3.88s\n",
      "| epoch  19 | train accuracy    0.655 | time:  3.87s\n",
      "| epoch  20 | train accuracy    0.661 | time:  3.88s\n",
      "| epoch  21 | train accuracy    0.659 | time:  4.00s\n",
      "| epoch  22 | train accuracy    0.659 | time:  3.95s\n",
      "| epoch  23 | train accuracy    0.658 | time:  4.23s\n",
      "| epoch  24 | train accuracy    0.661 | time:  3.91s\n",
      "| epoch  25 | train accuracy    0.660 | time:  4.00s\n",
      "| epoch  26 | train accuracy    0.658 | time:  3.88s\n",
      "| epoch  27 | train accuracy    0.663 | time:  4.01s\n",
      "| epoch  28 | train accuracy    0.660 | time:  4.00s\n",
      "| epoch  29 | train accuracy    0.669 | time:  3.98s\n",
      "| epoch  30 | train accuracy    0.665 | time:  4.04s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(meta_model, train_loader, \"engineered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e474de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6570669029685423"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(meta_model, val_loader, \"engineered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d90c7",
   "metadata": {},
   "source": [
    "## Combined Feature Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.pipeline = nn.Sequential(\n",
    "            nn.Linear(num_features, 18), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 12), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 8), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, num_class)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_1, x_2 = x\n",
    "        x_1 = x_1.to(device)  \n",
    "        x_2 = x_2.to(device)\n",
    "        \n",
    "        # text pipeline: try embedding! \n",
    "        # x_1 = ...\n",
    "\n",
    "        # engineered features: fully-connected Linear layers are fine\n",
    "        # x_2 = ...\n",
    "\n",
    "        # ensure that both x_1 and x_2 are 2-d tensors, flattening if necessary\n",
    "        # then, combine them with: \n",
    "        x = torch.cat(x_1, x_2, 1)\n",
    "        # pass x through a couple more fully-connected layers and return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

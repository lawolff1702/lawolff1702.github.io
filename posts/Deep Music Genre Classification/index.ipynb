{
 "cells": [
  {
   "cell_type": "raw",
   "id": "04c770dc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Deep Music Genre Classification\n",
    "author: Lukka Wolff\n",
    "date: '2025-05-12'\n",
    "image: \"cover_image.png\"\n",
    "description: \"Deep Music Genre Classification in Python\"\n",
    "categories:\n",
    "    - Natural Language Processing\n",
    "    - Neural Networks\n",
    "    - Deep Learning\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b023326",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "In this blog post, we explore a deep learning approach to predicting the genres of music tracks. We leverage both song lyrics and engineered metadata features. We tokenize the lyrics with a BERT tokenizer and make use of Spotify's engineered audio–semantic features (e.g., acousticness, danceability, thematic tags). We implement three neural networks: a lyric-based model, a metadata-only network, and a combined network that uses both lyric embeddings and engineered features. We compare how our different models stack up against one another and our base rate to assess the success of our different approaches to genre prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94688b83",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dad640f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukka\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# for train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for suppressing bugged warnings from torchinfo\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)\n",
    "\n",
    "# tokenizers from HuggingFace\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# for building condensed vocab sets\n",
    "# from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72de72",
   "metadata": {},
   "source": [
    "We are loading in a [Kaggle dataset](https://www.kaggle.com/datasets/saurabhshahane/music-dataset-1950-to-2019) that contains information about music made between the years 1950 and 2019 collected through Spotify. The dataset contains lyrics, artist info, track names, etc. Importantly it also includes music metadata like sadness, danceability, loudness, acousticness, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f297de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/tcc_ceds_music.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c5b3e",
   "metadata": {},
   "source": [
    "Lets have a look at some of the raw data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58bdc5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>frankie laine</td>\n",
       "      <td>i believe</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>believe drop rain fall grow believe darkest ni...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.035537</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.443435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.331745</td>\n",
       "      <td>0.647540</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>world/life</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>johnnie ray</td>\n",
       "      <td>cry</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>sweetheart send letter goodbye secret feel bet...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.225422</td>\n",
       "      <td>0.456298</td>\n",
       "      <td>0.585288</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351814</td>\n",
       "      <td>0.139112</td>\n",
       "      <td>music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>pérez prado</td>\n",
       "      <td>patricia</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>kiss lips want stroll charm mambo chacha merin...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.744404</td>\n",
       "      <td>0.083935</td>\n",
       "      <td>0.199393</td>\n",
       "      <td>0.775350</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>giorgos papadopoulos</td>\n",
       "      <td>apopse eida oneiro</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>till darling till matter know till dream live ...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.417772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.291671</td>\n",
       "      <td>0.646489</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.597073</td>\n",
       "      <td>0.394375</td>\n",
       "      <td>romantic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           artist_name            track_name  release_date genre  \\\n",
       "0           0                mukesh  mohabbat bhi jhoothi          1950   pop   \n",
       "1           4         frankie laine             i believe          1950   pop   \n",
       "2           6           johnnie ray                   cry          1950   pop   \n",
       "3          10           pérez prado              patricia          1950   pop   \n",
       "4          12  giorgos papadopoulos    apopse eida oneiro          1950   pop   \n",
       "\n",
       "                                              lyrics  len    dating  violence  \\\n",
       "0  hold time feel break feel untrue convince spea...   95  0.000598  0.063746   \n",
       "1  believe drop rain fall grow believe darkest ni...   51  0.035537  0.096777   \n",
       "2  sweetheart send letter goodbye secret feel bet...   24  0.002770  0.002770   \n",
       "3  kiss lips want stroll charm mambo chacha merin...   54  0.048249  0.001548   \n",
       "4  till darling till matter know till dream live ...   48  0.001350  0.001350   \n",
       "\n",
       "   world/life  ...   sadness  feelings  danceability  loudness  acousticness  \\\n",
       "0    0.000598  ...  0.380299  0.117175      0.357739  0.454119      0.997992   \n",
       "1    0.443435  ...  0.001284  0.001284      0.331745  0.647540      0.954819   \n",
       "2    0.002770  ...  0.002770  0.225422      0.456298  0.585288      0.840361   \n",
       "3    0.001548  ...  0.225889  0.001548      0.686992  0.744404      0.083935   \n",
       "4    0.417772  ...  0.068800  0.001350      0.291671  0.646489      0.975904   \n",
       "\n",
       "   instrumentalness   valence    energy       topic  age  \n",
       "0          0.901822  0.339448  0.137110     sadness  1.0  \n",
       "1          0.000002  0.325021  0.263240  world/life  1.0  \n",
       "2          0.000000  0.351814  0.139112       music  1.0  \n",
       "3          0.199393  0.775350  0.743736    romantic  1.0  \n",
       "4          0.000246  0.597073  0.394375    romantic  1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c455d",
   "metadata": {},
   "source": [
    "Here is a brief look at how many songs we have in each represented genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2300648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "blues      4604\n",
       "country    5445\n",
       "hip hop     904\n",
       "jazz       3845\n",
       "pop        7042\n",
       "reggae     2498\n",
       "rock       4034\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"genre\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f7dcaf",
   "metadata": {},
   "source": [
    "This is a pretty large number of songs to classify... and some genres I personally dont care for. So, to make the dataframe more manageable and applicable to me personally, we are going to narrow down to only observe reggae, hip hop, rock and jazz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaaf27ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17091</th>\n",
       "      <td>54304</td>\n",
       "      <td>gene ammons</td>\n",
       "      <td>it's the talk of the town</td>\n",
       "      <td>1950</td>\n",
       "      <td>jazz</td>\n",
       "      <td>lovers sweethearts hard understand know happen...</td>\n",
       "      <td>61</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319570</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.352323</td>\n",
       "      <td>0.620388</td>\n",
       "      <td>0.868474</td>\n",
       "      <td>0.235830</td>\n",
       "      <td>0.430132</td>\n",
       "      <td>0.282260</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17092</th>\n",
       "      <td>54305</td>\n",
       "      <td>gene ammons</td>\n",
       "      <td>you go to my head</td>\n",
       "      <td>1950</td>\n",
       "      <td>jazz</td>\n",
       "      <td>head linger like haunt refrain spin round brai...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.340964</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>0.638541</td>\n",
       "      <td>0.907630</td>\n",
       "      <td>0.900810</td>\n",
       "      <td>0.221970</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>violence</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17093</th>\n",
       "      <td>54307</td>\n",
       "      <td>bud powell</td>\n",
       "      <td>yesterdays</td>\n",
       "      <td>1950</td>\n",
       "      <td>jazz</td>\n",
       "      <td>music speak start hear musicians like dizzy gi...</td>\n",
       "      <td>107</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.074762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.097082</td>\n",
       "      <td>0.489873</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.992972</td>\n",
       "      <td>0.927126</td>\n",
       "      <td>0.334295</td>\n",
       "      <td>0.228204</td>\n",
       "      <td>music</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17094</th>\n",
       "      <td>54311</td>\n",
       "      <td>tony bennett</td>\n",
       "      <td>stranger in paradise</td>\n",
       "      <td>1950</td>\n",
       "      <td>jazz</td>\n",
       "      <td>hand stranger paradise lose wonderland strange...</td>\n",
       "      <td>41</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.180524</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527429</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.179032</td>\n",
       "      <td>0.559470</td>\n",
       "      <td>0.983936</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.086974</td>\n",
       "      <td>0.235211</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17095</th>\n",
       "      <td>54313</td>\n",
       "      <td>dean martin</td>\n",
       "      <td>zing-a zing-a zing boom</td>\n",
       "      <td>1950</td>\n",
       "      <td>jazz</td>\n",
       "      <td>zinga zinga zinga zinga zinga zinga zinga zing...</td>\n",
       "      <td>160</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425721</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.580851</td>\n",
       "      <td>0.687409</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   artist_name                 track_name  release_date  \\\n",
       "17091       54304   gene ammons  it's the talk of the town          1950   \n",
       "17092       54305   gene ammons          you go to my head          1950   \n",
       "17093       54307    bud powell                 yesterdays          1950   \n",
       "17094       54311  tony bennett       stranger in paradise          1950   \n",
       "17095       54313   dean martin    zing-a zing-a zing boom          1950   \n",
       "\n",
       "      genre                                             lyrics  len    dating  \\\n",
       "17091  jazz  lovers sweethearts hard understand know happen...   61  0.001096   \n",
       "17092  jazz  head linger like haunt refrain spin round brai...   48  0.001754   \n",
       "17093  jazz  music speak start hear musicians like dizzy gi...  107  0.001144   \n",
       "17094  jazz  hand stranger paradise lose wonderland strange...   41  0.002105   \n",
       "17095  jazz  zinga zinga zinga zinga zinga zinga zinga zing...  160  0.001253   \n",
       "\n",
       "       violence  world/life  ...   sadness  feelings  danceability  loudness  \\\n",
       "17091  0.001096    0.001096  ...  0.319570  0.001096      0.352323  0.620388   \n",
       "17092  0.340964    0.001754  ...  0.001754  0.001754      0.379400  0.638541   \n",
       "17093  0.001144    0.074762  ...  0.001144  0.097082      0.489873  0.467400   \n",
       "17094  0.180524    0.002105  ...  0.527429  0.002105      0.179032  0.559470   \n",
       "17095  0.001253    0.001253  ...  0.425721  0.001253      0.580851  0.687409   \n",
       "\n",
       "       acousticness  instrumentalness   valence    energy     topic  age  \n",
       "17091      0.868474          0.235830  0.430132  0.282260   sadness  1.0  \n",
       "17092      0.907630          0.900810  0.221970  0.184159  violence  1.0  \n",
       "17093      0.992972          0.927126  0.334295  0.228204     music  1.0  \n",
       "17094      0.983936          0.001781  0.086974  0.235211   sadness  1.0  \n",
       "17095      0.655622          0.000000  0.936109  0.418400   sadness  1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = {\n",
    "    \"hip hop\"   : 0,\n",
    "    \"jazz\" : 1,\n",
    "    \"reggae\" : 2,\n",
    "    \"rock\" : 3,\n",
    "}\n",
    "\n",
    "df = df[df[\"genre\"].apply(lambda x: x in genres.keys())]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf486021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17091</th>\n",
       "      <td>54304</td>\n",
       "      <td>gene ammons</td>\n",
       "      <td>it's the talk of the town</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>lovers sweethearts hard understand know happen...</td>\n",
       "      <td>61</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319570</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.352323</td>\n",
       "      <td>0.620388</td>\n",
       "      <td>0.868474</td>\n",
       "      <td>0.235830</td>\n",
       "      <td>0.430132</td>\n",
       "      <td>0.282260</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17092</th>\n",
       "      <td>54305</td>\n",
       "      <td>gene ammons</td>\n",
       "      <td>you go to my head</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>head linger like haunt refrain spin round brai...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.340964</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>0.638541</td>\n",
       "      <td>0.907630</td>\n",
       "      <td>0.900810</td>\n",
       "      <td>0.221970</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>violence</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17093</th>\n",
       "      <td>54307</td>\n",
       "      <td>bud powell</td>\n",
       "      <td>yesterdays</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>music speak start hear musicians like dizzy gi...</td>\n",
       "      <td>107</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.074762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.097082</td>\n",
       "      <td>0.489873</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.992972</td>\n",
       "      <td>0.927126</td>\n",
       "      <td>0.334295</td>\n",
       "      <td>0.228204</td>\n",
       "      <td>music</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17094</th>\n",
       "      <td>54311</td>\n",
       "      <td>tony bennett</td>\n",
       "      <td>stranger in paradise</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>hand stranger paradise lose wonderland strange...</td>\n",
       "      <td>41</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.180524</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527429</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.179032</td>\n",
       "      <td>0.559470</td>\n",
       "      <td>0.983936</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.086974</td>\n",
       "      <td>0.235211</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17095</th>\n",
       "      <td>54313</td>\n",
       "      <td>dean martin</td>\n",
       "      <td>zing-a zing-a zing boom</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "      <td>zinga zinga zinga zinga zinga zinga zinga zing...</td>\n",
       "      <td>160</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425721</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.580851</td>\n",
       "      <td>0.687409</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28367</th>\n",
       "      <td>82447</td>\n",
       "      <td>mack 10</td>\n",
       "      <td>10 million ways</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>cause fuck leave scar tick tock clock come kno...</td>\n",
       "      <td>78</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065664</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.889527</td>\n",
       "      <td>0.759711</td>\n",
       "      <td>0.062549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751649</td>\n",
       "      <td>0.695686</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28368</th>\n",
       "      <td>82448</td>\n",
       "      <td>m.o.p.</td>\n",
       "      <td>ante up (robbin hoodz theory)</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>minks things chain ring braclets yap fame come...</td>\n",
       "      <td>67</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.035338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.789580</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.922712</td>\n",
       "      <td>0.797791</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28369</th>\n",
       "      <td>82449</td>\n",
       "      <td>nine</td>\n",
       "      <td>whutcha want?</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>get ban get ban stick crack relax plan attack ...</td>\n",
       "      <td>77</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.154302</td>\n",
       "      <td>0.168988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.663165</td>\n",
       "      <td>0.726970</td>\n",
       "      <td>0.104417</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.838211</td>\n",
       "      <td>0.767761</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28370</th>\n",
       "      <td>82450</td>\n",
       "      <td>will smith</td>\n",
       "      <td>switch</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>check check yeah yeah hear thing call switch g...</td>\n",
       "      <td>67</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.883028</td>\n",
       "      <td>0.786888</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.508450</td>\n",
       "      <td>0.885882</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28371</th>\n",
       "      <td>82451</td>\n",
       "      <td>jeezy</td>\n",
       "      <td>r.i.p.</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>remix killer alive remix thriller trap bitch s...</td>\n",
       "      <td>83</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>0.828875</td>\n",
       "      <td>0.674794</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475474</td>\n",
       "      <td>0.492477</td>\n",
       "      <td>obscene</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11281 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   artist_name                     track_name  release_date  \\\n",
       "17091       54304   gene ammons      it's the talk of the town          1950   \n",
       "17092       54305   gene ammons              you go to my head          1950   \n",
       "17093       54307    bud powell                     yesterdays          1950   \n",
       "17094       54311  tony bennett           stranger in paradise          1950   \n",
       "17095       54313   dean martin        zing-a zing-a zing boom          1950   \n",
       "...           ...           ...                            ...           ...   \n",
       "28367       82447       mack 10                10 million ways          2019   \n",
       "28368       82448        m.o.p.  ante up (robbin hoodz theory)          2019   \n",
       "28369       82449          nine                  whutcha want?          2019   \n",
       "28370       82450    will smith                         switch          2019   \n",
       "28371       82451         jeezy                         r.i.p.          2019   \n",
       "\n",
       "       genre                                             lyrics  len  \\\n",
       "17091      1  lovers sweethearts hard understand know happen...   61   \n",
       "17092      1  head linger like haunt refrain spin round brai...   48   \n",
       "17093      1  music speak start hear musicians like dizzy gi...  107   \n",
       "17094      1  hand stranger paradise lose wonderland strange...   41   \n",
       "17095      1  zinga zinga zinga zinga zinga zinga zinga zing...  160   \n",
       "...      ...                                                ...  ...   \n",
       "28367      0  cause fuck leave scar tick tock clock come kno...   78   \n",
       "28368      0  minks things chain ring braclets yap fame come...   67   \n",
       "28369      0  get ban get ban stick crack relax plan attack ...   77   \n",
       "28370      0  check check yeah yeah hear thing call switch g...   67   \n",
       "28371      0  remix killer alive remix thriller trap bitch s...   83   \n",
       "\n",
       "         dating  violence  world/life  ...   sadness  feelings  danceability  \\\n",
       "17091  0.001096  0.001096    0.001096  ...  0.319570  0.001096      0.352323   \n",
       "17092  0.001754  0.340964    0.001754  ...  0.001754  0.001754      0.379400   \n",
       "17093  0.001144  0.001144    0.074762  ...  0.001144  0.097082      0.489873   \n",
       "17094  0.002105  0.180524    0.002105  ...  0.527429  0.002105      0.179032   \n",
       "17095  0.001253  0.001253    0.001253  ...  0.425721  0.001253      0.580851   \n",
       "...         ...       ...         ...  ...       ...       ...           ...   \n",
       "28367  0.001350  0.001350    0.001350  ...  0.065664  0.001350      0.889527   \n",
       "28368  0.001284  0.001284    0.035338  ...  0.001284  0.001284      0.662082   \n",
       "28369  0.001504  0.154302    0.168988  ...  0.001504  0.001504      0.663165   \n",
       "28370  0.001196  0.001196    0.001196  ...  0.001196  0.001196      0.883028   \n",
       "28371  0.001012  0.075202    0.001012  ...  0.001012  0.033995      0.828875   \n",
       "\n",
       "       loudness  acousticness  instrumentalness   valence    energy     topic  \\\n",
       "17091  0.620388      0.868474          0.235830  0.430132  0.282260   sadness   \n",
       "17092  0.638541      0.907630          0.900810  0.221970  0.184159  violence   \n",
       "17093  0.467400      0.992972          0.927126  0.334295  0.228204     music   \n",
       "17094  0.559470      0.983936          0.001781  0.086974  0.235211   sadness   \n",
       "17095  0.687409      0.655622          0.000000  0.936109  0.418400   sadness   \n",
       "...         ...           ...               ...       ...       ...       ...   \n",
       "28367  0.759711      0.062549          0.000000  0.751649  0.695686   obscene   \n",
       "28368  0.789580      0.004607          0.000002  0.922712  0.797791   obscene   \n",
       "28369  0.726970      0.104417          0.000001  0.838211  0.767761   obscene   \n",
       "28370  0.786888      0.007027          0.000503  0.508450  0.885882   obscene   \n",
       "28371  0.674794      0.015862          0.000000  0.475474  0.492477   obscene   \n",
       "\n",
       "            age  \n",
       "17091  1.000000  \n",
       "17092  1.000000  \n",
       "17093  1.000000  \n",
       "17094  1.000000  \n",
       "17095  1.000000  \n",
       "...         ...  \n",
       "28367  0.014286  \n",
       "28368  0.014286  \n",
       "28369  0.014286  \n",
       "28370  0.014286  \n",
       "28371  0.014286  \n",
       "\n",
       "[11281 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"genre\"] = df[\"genre\"].apply(genres.get)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08060709",
   "metadata": {},
   "source": [
    "The base rate on our classification is the proportion of the data set occupied by the largest label class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7065f720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "0    0.080135\n",
       "1    0.340839\n",
       "2    0.221434\n",
       "3    0.357592\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"genre\").size() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd47316",
   "metadata": {},
   "source": [
    "If we always guessed category 3, then we would expect an accuracy of **roughly 36%**. So, our task will be to see whether we can train a model to beat this. \n",
    "\n",
    "As we try to predict the genre of the track, we will use lyrics alongside some other engineered features (metadata) that we define below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bccea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features = ['dating', 'violence', 'world/life', 'night/time','shake the audience','family/gospel', 'romantic', 'communication','obscene', 'music', 'movement/places', 'light/visual perceptions','family/spiritual', 'like/girls', 'sadness', 'feelings', 'danceability','loudness', 'acousticness', 'instrumentalness', 'valence', 'energy']      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78aed25",
   "metadata": {},
   "source": [
    "Our models will only need these engineered features, lyrics, and our target value which will be *genre* so we can throw them all into the same dataframe and use slicing to access different parts later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e570cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>night/time</th>\n",
       "      <th>shake the audience</th>\n",
       "      <th>family/gospel</th>\n",
       "      <th>romantic</th>\n",
       "      <th>communication</th>\n",
       "      <th>obscene</th>\n",
       "      <th>music</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17091</th>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.036316</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.460773</td>\n",
       "      <td>0.086498</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319570</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.352323</td>\n",
       "      <td>0.620388</td>\n",
       "      <td>0.868474</td>\n",
       "      <td>0.235830</td>\n",
       "      <td>0.430132</td>\n",
       "      <td>0.282260</td>\n",
       "      <td>lovers sweethearts hard understand know happen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17092</th>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.340964</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.131872</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>0.638541</td>\n",
       "      <td>0.907630</td>\n",
       "      <td>0.900810</td>\n",
       "      <td>0.221970</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>head linger like haunt refrain spin round brai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17093</th>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.074762</td>\n",
       "      <td>0.046173</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.018789</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.421734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.097082</td>\n",
       "      <td>0.489873</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.992972</td>\n",
       "      <td>0.927126</td>\n",
       "      <td>0.334295</td>\n",
       "      <td>0.228204</td>\n",
       "      <td>music speak start hear musicians like dizzy gi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17094</th>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.180524</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.201965</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527429</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.179032</td>\n",
       "      <td>0.559470</td>\n",
       "      <td>0.983936</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.086974</td>\n",
       "      <td>0.235211</td>\n",
       "      <td>hand stranger paradise lose wonderland strange...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17095</th>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.081126</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.111951</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.268737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425721</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.580851</td>\n",
       "      <td>0.687409</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>zinga zinga zinga zinga zinga zinga zinga zing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dating  violence  world/life  night/time  shake the audience  \\\n",
       "17091  0.001096  0.001096    0.001096    0.001096            0.036316   \n",
       "17092  0.001754  0.340964    0.001754    0.001754            0.001754   \n",
       "17093  0.001144  0.001144    0.074762    0.046173            0.001144   \n",
       "17094  0.002105  0.180524    0.002105    0.002105            0.002105   \n",
       "17095  0.001253  0.001253    0.001253    0.001253            0.001253   \n",
       "\n",
       "       family/gospel  romantic  communication   obscene     music  ...  \\\n",
       "17091       0.001096  0.001096       0.460773  0.086498  0.001096  ...   \n",
       "17092       0.001754  0.131872       0.001754  0.001754  0.001754  ...   \n",
       "17093       0.018789  0.001144       0.001655  0.001144  0.421734  ...   \n",
       "17094       0.002105  0.002105       0.201965  0.002105  0.002105  ...   \n",
       "17095       0.081126  0.001253       0.111951  0.001253  0.268737  ...   \n",
       "\n",
       "        sadness  feelings  danceability  loudness  acousticness  \\\n",
       "17091  0.319570  0.001096      0.352323  0.620388      0.868474   \n",
       "17092  0.001754  0.001754      0.379400  0.638541      0.907630   \n",
       "17093  0.001144  0.097082      0.489873  0.467400      0.992972   \n",
       "17094  0.527429  0.002105      0.179032  0.559470      0.983936   \n",
       "17095  0.425721  0.001253      0.580851  0.687409      0.655622   \n",
       "\n",
       "       instrumentalness   valence    energy  \\\n",
       "17091          0.235830  0.430132  0.282260   \n",
       "17092          0.900810  0.221970  0.184159   \n",
       "17093          0.927126  0.334295  0.228204   \n",
       "17094          0.001781  0.086974  0.235211   \n",
       "17095          0.000000  0.936109  0.418400   \n",
       "\n",
       "                                                  lyrics  genre  \n",
       "17091  lovers sweethearts hard understand know happen...      1  \n",
       "17092  head linger like haunt refrain spin round brai...      1  \n",
       "17093  music speak start hear musicians like dizzy gi...      1  \n",
       "17094  hand stranger paradise lose wonderland strange...      1  \n",
       "17095  zinga zinga zinga zinga zinga zinga zinga zing...      1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean= df[engineered_features + ['lyrics', 'genre']].copy()\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdb0d67",
   "metadata": {},
   "source": [
    "Finally, we will perform a train-validation split to later evaluate our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d16bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_clean,shuffle = True, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731b78b",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7172d9",
   "metadata": {},
   "source": [
    "We now need to *vectorize* the lyrics. We’re going to use **tokenization** to break up the lyrics into a sequence of tokens, and then vectorize that sequence.\n",
    "\n",
    "We will be using a tokenizer imported from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df0d265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c770c",
   "metadata": {},
   "source": [
    "For our purposes it’s more convenient to assign an *integer* to each token, which we can do like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a11810f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 15662, 2189, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tokenizer(\"I love reggae music!\")\n",
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbfa921",
   "metadata": {},
   "source": [
    "To do the reverse, we can use the `.decode` method of the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e21097f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] i love reggae music! [SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e26c5",
   "metadata": {},
   "source": [
    "Here is some code to help us prepare our dataset with encodings. A lot of our lyrics are different lengths so we will pad the shorter ones with 0s and truncate others that are especially long. We will make use of the torch `Dataset` class to help manage our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "067e73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512 # BERT capacity\n",
    "\n",
    "def preprocess(df, tokenizer, max_len):\n",
    "    lyrics_tokens = tokenizer(list(df[\"lyrics\"]), padding=\"max_length\", truncation=True, max_length=max_len)[\"input_ids\"]\n",
    "    engineered = df[engineered_features].values.tolist()\n",
    "    y = list(df[\"genre\"])\n",
    "    return lyrics_tokens, engineered, y\n",
    "\n",
    "class TextDataFromDF(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.lyrics_tokens, self.engineered_feats, self.y = preprocess(df, tokenizer, max_len)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.lyrics_tokens[ix], self.engineered_feats[ix], self.y[ix]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb98b2",
   "metadata": {},
   "source": [
    "Lets make our encoded datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09224851",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TextDataFromDF(df_train)\n",
    "val_data   = TextDataFromDF(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7df72",
   "metadata": {},
   "source": [
    "Here is what a single songs information looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff257b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2372, 2113, 21209, 6887, 16585, 2477, 2111, 8501, 3613, 9266, 2213, 9680, 2444, 9152, 23033, 2015, 10675, 2015, 4401, 2991, 4533, 4952, 11898, 10432, 12170, 9102, 6510, 8081, 4485, 2729, 10667, 14033, 6510, 2131, 2477, 2175, 4485, 2131, 2518, 3861, 2272, 2420, 2208, 16371, 4246, 7047, 8046, 4485, 2215, 4485, 4248, 4355, 7281, 7579, 6841, 16360, 8091, 4485, 4982, 4503, 14255, 23344, 2227, 2131, 3947, 3238, 2444, 11565, 10020, 2102, 3305, 2514, 2665, 3259, 2192, 2518, 2903, 2066, 8554, 10421, 7200, 5223, 2342, 2757, 11274, 4372, 14540, 10696, 2111, 2219, 3828, 2111, 13660, 3240, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0.0011961722985867, 0.1300521675514939, 0.1951359532512352, 0.0011961722561089, 0.0011961723204168, 0.0011961722655141, 0.0011961722799619, 0.1710064773999869, 0.3944457875450848, 0.0011961722772403, 0.0011961723013686, 0.0011961723181082, 0.0522687272336512, 0.0011961722965877, 0.0011961723815529, 0.0415406469256242, 0.4476334885735947, 0.7206368740866087, 0.0736938490902099, 0.0, 0.6589035449299256, 0.6446335461127515]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "X_tokens, X_feats, y = train_data[1]\n",
    "print(X_tokens, X_feats)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e2e76",
   "metadata": {},
   "source": [
    "We are going to be feeding data in in batches, so we will need a dataloader which necessitates a collate function to ensure our we are imputing tensors of the right size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a751a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(data):\n",
    "    tokens = torch.tensor([d[0] for d in data], dtype=torch.long)\n",
    "    engineered = torch.tensor([d[1] for d in data], dtype=torch.float)\n",
    "    y = torch.tensor([d[2] for d in data], dtype=torch.long)\n",
    "    return (tokens, engineered), y\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, collate_fn = collate)\n",
    "val_loader = DataLoader(val_data, batch_size=8, shuffle=True, collate_fn = collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cb3a6e",
   "metadata": {},
   "source": [
    "Here is what a batch of data looks like. The predictor data is now a tensor in which the entries give token indices, padded with 0s and another tensor with the  values of our engineered features. For visualization purposes we’ll show only the first 2 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b18de88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  2621,  4553,  ...,     0,     0,     0],\n",
       "         [  101,  2668, 14740,  ...,     0,     0,     0],\n",
       "         [  101,  2305,  2272,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2051,  2621,  ...,     0,     0,     0],\n",
       "         [  101,  2051,  2202,  ...,     0,     0,     0],\n",
       "         [  101,  5949,  2773,  ...,     0,     0,     0]]),\n",
       " tensor([[2.5063e-03, 2.5063e-03, 3.3226e-01, 9.8139e-02, 2.5063e-03, 2.5063e-03,\n",
       "          2.5063e-03, 2.5063e-03, 2.5063e-03, 1.2809e-01, 2.5063e-03, 2.5063e-03,\n",
       "          2.5063e-03, 2.8335e-01, 2.5063e-03, 2.5063e-03, 5.5594e-01, 7.7276e-01,\n",
       "          2.0883e-02, 1.1235e-05, 2.8174e-01, 4.7846e-01],\n",
       "         [1.8797e-03, 5.0473e-01, 1.8797e-03, 1.8797e-03, 3.7594e-02, 3.9971e-02,\n",
       "          1.8797e-03, 1.8797e-03, 1.8797e-03, 1.8797e-03, 1.8797e-03, 1.8797e-03,\n",
       "          1.3261e-01, 1.8797e-03, 2.2307e-01, 1.8797e-03, 8.1155e-01, 7.5999e-01,\n",
       "          8.7248e-02, 2.5304e-03, 5.6513e-01, 6.5364e-01],\n",
       "         [1.9493e-03, 1.9493e-03, 3.4622e-01, 1.9493e-03, 1.9493e-03, 1.9493e-03,\n",
       "          1.9493e-03, 1.9493e-03, 1.9493e-03, 1.9493e-03, 2.8898e-01, 3.3361e-01,\n",
       "          1.9493e-03, 1.9493e-03, 1.9493e-03, 1.9493e-03, 6.1118e-01, 5.5086e-01,\n",
       "          9.5181e-01, 1.8725e-01, 3.4151e-01, 2.2320e-01],\n",
       "         [5.7208e-04, 5.7208e-04, 5.1883e-02, 5.7208e-04, 6.8732e-02, 2.8145e-02,\n",
       "          5.7208e-04, 2.5657e-01, 3.6477e-01, 5.7208e-04, 2.2247e-01, 5.7208e-04,\n",
       "          5.7208e-04, 5.7208e-04, 5.7208e-04, 5.7208e-04, 7.4764e-01, 6.9715e-01,\n",
       "          1.6867e-01, 0.0000e+00, 8.4233e-01, 4.8046e-01],\n",
       "         [1.9611e-02, 3.9300e-01, 2.4161e-01, 8.9206e-04, 1.8294e-02, 7.0961e-02,\n",
       "          8.9206e-04, 8.9206e-04, 8.9206e-04, 8.9206e-04, 8.9206e-04, 1.4598e-01,\n",
       "          4.5708e-02, 5.5025e-02, 8.9206e-04, 8.9206e-04, 8.0180e-01, 6.7451e-01,\n",
       "          5.6827e-05, 9.4838e-01, 9.0210e-01, 7.9379e-01],\n",
       "         [1.0526e-03, 1.0526e-03, 1.0526e-03, 3.2379e-01, 1.0526e-03, 1.0526e-03,\n",
       "          9.0729e-02, 1.7966e-01, 1.0526e-03, 1.0713e-01, 1.0526e-03, 2.5740e-01,\n",
       "          1.0526e-03, 1.0526e-03, 1.0526e-03, 2.7609e-02, 2.0286e-01, 6.0398e-01,\n",
       "          9.4478e-01, 5.6883e-05, 5.1731e-02, 2.8426e-01],\n",
       "         [1.5038e-03, 1.8747e-01, 1.5038e-03, 1.6175e-01, 1.5038e-03, 1.5038e-03,\n",
       "          1.5038e-03, 1.5038e-03, 4.1537e-02, 1.5038e-03, 1.5038e-03, 1.5038e-03,\n",
       "          1.5038e-03, 1.5038e-03, 5.2697e-01, 1.5038e-03, 5.4403e-01, 7.8607e-01,\n",
       "          6.8374e-06, 8.3806e-01, 3.3739e-01, 9.4795e-01],\n",
       "         [2.9240e-03, 2.9240e-03, 2.9240e-03, 1.0013e-01, 2.9240e-03, 2.9240e-03,\n",
       "          2.9240e-03, 2.9240e-03, 2.9240e-03, 1.7470e-01, 2.9240e-03, 2.9240e-03,\n",
       "          2.9240e-03, 9.0332e-02, 4.7758e-01, 2.9240e-03, 6.3609e-01, 7.2769e-01,\n",
       "          5.7932e-01, 3.3603e-01, 6.4963e-01, 7.6075e-01]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13b5056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2550573",
   "metadata": {},
   "source": [
    "# Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f5663f",
   "metadata": {},
   "source": [
    "We are going to train **three** neural networks to classify our genres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b18f5e7",
   "metadata": {},
   "source": [
    "- Using Lyrics to Classify\n",
    "- Using Engineered Features (Metadata) to Classify\n",
    "- Using Lyrics and Metadata to Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dffc3d",
   "metadata": {},
   "source": [
    "Lets build a model for classifying genres based on lyrics first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1eb253",
   "metadata": {},
   "source": [
    "## Lyrical Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aba4f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size, embedding_dim, max_len, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size+1, embedding_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc_flat = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, num_class) # max_len*embedding_dim\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.fc_flat(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.mean(axis = 1)\n",
    "        # x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb0291",
   "metadata": {},
   "source": [
    "Our model begins with the embedding layer where each word is looked up in an embedding table and turned into a learned vector of size `embedding_dim`.  Immediately after embedding, we pass each token’s embedding through a small fully-connected layer then a ReLU activation, the fully connected layer lets the model learn a richer representation before pooling. We then pass the embedding into a dropout layer where 20% of the embedding vectors are randomly zeroed. This is a form of regularization step meant to help us not be over-reliant on certain tokens. Our mean-pool layer reduces our dimension by averaging all token embeddings so each song is now a fixed-size vector. Finally, our linear layer gives us our probabilities for each genre.\n",
    "\n",
    "Let's have a look at it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ec0d5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.vocab)\n",
    "embedding_dim = 32\n",
    "num_class = len(genres)\n",
    "\n",
    "text_model = TextClassificationModel(vocab_size, embedding_dim, max_len, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7a935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "TextClassificationModel                  --\n",
       "├─Embedding: 1-1                         976,736\n",
       "├─Dropout: 1-2                           --\n",
       "├─Linear: 1-3                            1,056\n",
       "├─Linear: 1-4                            132\n",
       "├─ReLU: 1-5                              --\n",
       "=================================================================\n",
       "Total params: 977,924\n",
       "Trainable params: 977,924\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(text_model, input_Size = (8, max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529a1b8",
   "metadata": {},
   "source": [
    "We have a huge amount of trainable parameters! We could make this architecture more lightweight by changing the size of our embedding dimension.\n",
    "\n",
    "Below, we define our training loop which can be used for all of our three models that we will define shortly. We define an accuracy function that we will use to evaluate the accuracy of our model and another to evaluate the per class accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, mode=\"lyrics\", vocab_freq=False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "    # keep track of some counts for measuring accuracy\n",
    "    total_acc, total_count = 0, 0\n",
    "    \n",
    "    for X, y in dataloader:\n",
    "        # unpack and move to device\n",
    "        tokens, engineered = X\n",
    "        y = y.to(device)\n",
    "\n",
    "        if mode == \"lyrics\":\n",
    "            \"\"\"\n",
    "            if vocab_freq:\n",
    "                vocab = build_vocab_from_iterator(tokens, specials=[\"<unk>\"], min_freq = 50)\n",
    "                tokens = torch.tensor(vocab)\n",
    "            \"\"\"\n",
    "            data = tokens.to(device)\n",
    "        elif mode == \"engineered\":\n",
    "            data = engineered.to(device)\n",
    "        else:\n",
    "            data = X\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # form prediction on batch\n",
    "        predicted_label = model(data)\n",
    "        # evaluate loss on prediction\n",
    "        loss = loss_fn(predicted_label, y)\n",
    "        # compute gradient\n",
    "        loss.backward()\n",
    "        # take an optimization step\n",
    "        optimizer.step()\n",
    "                \n",
    "        # for printing accuracy\n",
    "        total_acc += (predicted_label.argmax(1) == y).sum().item()\n",
    "        total_count += y.size(0)\n",
    "\n",
    "    print(f'| epoch {epoch:3d} | train accuracy {total_acc/total_count:8.3f} | time: {time.time() - epoch_start_time:5.2f}s')\n",
    "\n",
    "def accuracy(model, dataloader, mode=\"lyrics\"):\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # unpack and move to device\n",
    "            tokens, engineered = X\n",
    "            y = y.to(device)\n",
    "\n",
    "            if mode == \"lyrics\":\n",
    "                data = tokens.to(device)\n",
    "            elif mode == \"engineered\":\n",
    "                data = engineered.to(device)\n",
    "            elif mode == \"both\":\n",
    "                data = X\n",
    "\n",
    "            predicted_label = model(data)\n",
    "            total_acc += (predicted_label.argmax(1) == y).sum().item()\n",
    "            total_count += y.size(0)\n",
    "    return total_acc/total_count\n",
    "\n",
    "def per_class_accuracy(model, dataloader, mode=\"lyrics\", num_classes=4):\n",
    "    model.eval()\n",
    "    correct = [0] * num_classes\n",
    "    total   = [0] * num_classes\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            tokens, engineered = X\n",
    "            y = y.to(device)\n",
    "\n",
    "            if mode == \"lyrics\":\n",
    "                data = tokens.to(device)\n",
    "            elif mode == \"engineered\":\n",
    "                data = engineered.to(device)\n",
    "            else:\n",
    "                data = X\n",
    "\n",
    "            outputs = model(data)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            for cls in range(len(correct)):\n",
    "                mask = (y == cls)\n",
    "                total[cls] += mask.sum().item()\n",
    "                correct[cls] += ((preds == cls) & mask).sum().item()\n",
    "\n",
    "    return {\n",
    "        cls: (correct[cls] / total[cls] if total[cls] > 0 else 0.0)\n",
    "        for cls in range(len(correct))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b0cbc",
   "metadata": {},
   "source": [
    "Now that we have those functions, lets jump right in and see how our model does when training on lyrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b5303ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | train accuracy    0.379 | time:  4.47s\n",
      "     test accuracy   0.3540097474523704\n",
      "| epoch   2 | train accuracy    0.398 | time:  3.97s\n",
      "     test accuracy   0.39787328311918474\n",
      "| epoch   3 | train accuracy    0.425 | time:  3.94s\n",
      "     test accuracy   0.4262295081967213\n",
      "| epoch   4 | train accuracy    0.457 | time:  4.03s\n",
      "     test accuracy   0.42977403633141337\n",
      "| epoch   5 | train accuracy    0.498 | time:  4.06s\n",
      "     test accuracy   0.46256092157731504\n",
      "| epoch   6 | train accuracy    0.556 | time:  3.77s\n",
      "     test accuracy   0.4980062029242357\n",
      "| epoch   7 | train accuracy    0.600 | time:  3.75s\n",
      "     test accuracy   0.538325210456358\n",
      "| epoch   8 | train accuracy    0.642 | time:  3.64s\n",
      "     test accuracy   0.5578201151971643\n",
      "| epoch   9 | train accuracy    0.674 | time:  3.64s\n",
      "     test accuracy   0.5604785112981834\n",
      "| epoch  10 | train accuracy    0.695 | time:  3.67s\n",
      "     test accuracy   0.5746566238369517\n",
      "| epoch  11 | train accuracy    0.712 | time:  3.68s\n",
      "     test accuracy   0.5813026140894993\n",
      "| epoch  12 | train accuracy    0.729 | time:  3.74s\n",
      "     test accuracy   0.5795303500221533\n",
      "| epoch  13 | train accuracy    0.745 | time:  4.02s\n",
      "     test accuracy   0.5724412937527692\n",
      "| epoch  14 | train accuracy    0.757 | time:  3.94s\n",
      "     test accuracy   0.5777580859548073\n",
      "| epoch  15 | train accuracy    0.767 | time:  4.04s\n",
      "     test accuracy   0.5764288879042977\n",
      "| epoch  16 | train accuracy    0.782 | time:  3.85s\n",
      "     test accuracy   0.5746566238369517\n",
      "| epoch  17 | train accuracy    0.795 | time:  3.86s\n",
      "     test accuracy   0.5755427558706248\n",
      "| epoch  18 | train accuracy    0.799 | time:  3.91s\n",
      "     test accuracy   0.5684536996012406\n",
      "| epoch  19 | train accuracy    0.813 | time:  4.09s\n",
      "     test accuracy   0.5755427558706248\n",
      "| epoch  20 | train accuracy    0.821 | time:  3.99s\n",
      "     test accuracy   0.5737704918032787\n",
      "| epoch  21 | train accuracy    0.831 | time:  4.46s\n",
      "     test accuracy   0.5693398316349136\n",
      "| epoch  22 | train accuracy    0.840 | time:  4.20s\n",
      "     test accuracy   0.5742135578201152\n",
      "| epoch  23 | train accuracy    0.849 | time:  4.23s\n",
      "     test accuracy   0.5622507753655295\n",
      "| epoch  24 | train accuracy    0.857 | time:  4.39s\n",
      "     test accuracy   0.561807709348693\n",
      "| epoch  25 | train accuracy    0.859 | time:  4.26s\n",
      "     test accuracy   0.562693841382366\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(text_model, train_loader, \"lyrics\")\n",
    "    print(\"     test accuracy  \", accuracy(text_model, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3e236043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5666814355338945"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(text_model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc08b66",
   "metadata": {},
   "source": [
    "An **accuracy around 56%** may not seem all that great at first glance... however, lets remember our base rate was 36%, so despite the fact that we don't have a particularly high accuracy we can still say that this model is successful!\n",
    "\n",
    "Let's look at our accuracy on each of our genres. A quick reminder that our genre keys are:\n",
    "- hip hop: 0\n",
    "- jazz: 1\n",
    "- reggae: 2\n",
    "- rock: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7446aa6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.47701149425287354,\n",
       " 1: 0.5816326530612245,\n",
       " 2: 0.5031055900621118,\n",
       " 3: 0.6090686274509803}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_accuracy(text_model, val_loader, mode=\"lyrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed78a2",
   "metadata": {},
   "source": [
    "Even our weakest genre (hip hop at around 48%) comfortably exceeds the base rate! Our model is indeed learning useful signals from the lyrics. Our best performances were on jazz and rock that may suggest that those lyrics have more distinct stylistic patterns. Hip hop and reggae, on the other hand, may have suffered because of slang or patois lyrics or possibly thematic overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b6cc38",
   "metadata": {},
   "source": [
    "## Engineered Features Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba498b34",
   "metadata": {},
   "source": [
    "Let's tackle using our engineered features to try and determine song genres!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3c49c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_class):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.pipeline = nn.Sequential(\n",
    "            nn.Linear(num_features, 18), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 12), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 8), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, num_class)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipeline(x)\n",
    "\n",
    "    def predict(self, x): \n",
    "        return self.score(x) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0fcc3f",
   "metadata": {},
   "source": [
    "This is a pretty simple architecture for our engineered features of which there are twenty-two. We are using a series of fully-connected linear layers, each punctuated by a ReLU nonlinearity activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c92120b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MetadataClassificationModel              --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Linear: 2-1                       414\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Linear: 2-3                       228\n",
       "│    └─ReLU: 2-4                         --\n",
       "│    └─Linear: 2-5                       104\n",
       "│    └─ReLU: 2-6                         --\n",
       "│    └─Linear: 2-7                       36\n",
       "=================================================================\n",
       "Total params: 782\n",
       "Trainable params: 782\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = len(engineered_features)\n",
    "\n",
    "meta_model = MetadataClassificationModel(num_features, num_class).to(device)\n",
    "summary(meta_model, input_Size = (8, max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb732265",
   "metadata": {},
   "source": [
    "This model is pretty lightweight compared to the lyric based model. Lets see how it performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3f986713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | train accuracy    0.459 | time:  4.19s\n",
      "     test accuracy   0.5002215330084182\n",
      "| epoch   2 | train accuracy    0.589 | time:  4.00s\n",
      "     test accuracy   0.615861763402747\n",
      "| epoch   3 | train accuracy    0.636 | time:  4.65s\n",
      "     test accuracy   0.6278245458573327\n",
      "| epoch   4 | train accuracy    0.643 | time:  3.95s\n",
      "     test accuracy   0.6371289322108994\n",
      "| epoch   5 | train accuracy    0.645 | time:  3.90s\n",
      "     test accuracy   0.6371289322108994\n",
      "| epoch   6 | train accuracy    0.650 | time:  3.75s\n",
      "     test accuracy   0.640230394328755\n",
      "| epoch   7 | train accuracy    0.649 | time:  3.73s\n",
      "     test accuracy   0.6357997341603899\n",
      "| epoch   8 | train accuracy    0.652 | time:  3.78s\n",
      "     test accuracy   0.642002658396101\n",
      "| epoch   9 | train accuracy    0.649 | time:  3.51s\n",
      "     test accuracy   0.6468763845813026\n",
      "| epoch  10 | train accuracy    0.651 | time:  3.73s\n",
      "     test accuracy   0.640230394328755\n",
      "| epoch  11 | train accuracy    0.649 | time:  3.52s\n",
      "     test accuracy   0.6513070447496677\n",
      "| epoch  12 | train accuracy    0.654 | time:  3.54s\n",
      "     test accuracy   0.641116526362428\n",
      "| epoch  13 | train accuracy    0.654 | time:  3.74s\n",
      "     test accuracy   0.6504209127159947\n",
      "| epoch  14 | train accuracy    0.655 | time:  3.39s\n",
      "     test accuracy   0.6526362428001772\n",
      "| epoch  15 | train accuracy    0.656 | time:  3.48s\n",
      "     test accuracy   0.6424457244129376\n",
      "| epoch  16 | train accuracy    0.654 | time:  3.31s\n",
      "     test accuracy   0.6464333185644661\n",
      "| epoch  17 | train accuracy    0.657 | time:  3.27s\n",
      "     test accuracy   0.6451041205139566\n",
      "| epoch  18 | train accuracy    0.654 | time:  3.38s\n",
      "     test accuracy   0.6442179884802836\n",
      "| epoch  19 | train accuracy    0.658 | time:  3.29s\n",
      "     test accuracy   0.642002658396101\n",
      "| epoch  20 | train accuracy    0.660 | time:  3.32s\n",
      "     test accuracy   0.6446610544971201\n",
      "| epoch  21 | train accuracy    0.658 | time:  3.24s\n",
      "     test accuracy   0.6477625166149756\n",
      "| epoch  22 | train accuracy    0.657 | time:  3.14s\n",
      "     test accuracy   0.6482055826318122\n",
      "| epoch  23 | train accuracy    0.658 | time:  3.21s\n",
      "     test accuracy   0.6477625166149756\n",
      "| epoch  24 | train accuracy    0.656 | time:  3.17s\n",
      "     test accuracy   0.6455471865307931\n",
      "| epoch  25 | train accuracy    0.655 | time:  3.09s\n",
      "     test accuracy   0.6530793088170137\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(meta_model, train_loader, \"engineered\")\n",
    "    print(\"     test accuracy  \", accuracy(meta_model, val_loader, \"engineered\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5e474de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6530793088170137"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(meta_model, val_loader, \"engineered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07155995",
   "metadata": {},
   "source": [
    "Woah! Only using metadata, we achieved **around 65% accuracy**! This much better than our base rate, and higher than the lyrics only classification approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a022208f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5689655172413793,\n",
       " 1: 0.6224489795918368,\n",
       " 2: 0.6128364389233955,\n",
       " 3: 0.7242647058823529}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_accuracy(meta_model, val_loader, mode=\"engineered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0cf02",
   "metadata": {},
   "source": [
    "We are also outperforming all of our base rates for each genre! Once again rock is our highest performer (around 72%) showing its distinction from other genres in categories like `instrumentalness`, `energy`, `movement/places`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d90c7",
   "metadata": {},
   "source": [
    "## Combined Feature Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece46e52",
   "metadata": {},
   "source": [
    "We have now explored successful approaches using lyrics and using metadata. Lets see how we perform when we combine the two!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eba8a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, num_class, num_features):\n",
    "        super().__init__()\n",
    "    \n",
    "        # engineered features pipeline\n",
    "        self.eng_pipeline = nn.Sequential(\n",
    "            nn.Linear(num_features, 18), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 12), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 8)\n",
    "            )\n",
    "        \n",
    "        # text pipeline \n",
    "        self.embedding = nn.Embedding(vocab_size+1, embedding_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(embedding_dim, 8)\n",
    "\n",
    "        # combine the two pipelines\n",
    "        self.combine = nn.Sequential(\n",
    "            nn.Linear(16, 12), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 8), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, num_class)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_text, x_eng = x\n",
    "        x_text = x_text.to(device)  \n",
    "        x_eng = x_eng.to(device)\n",
    "        \n",
    "        # text pipeline:\n",
    "        x_text = self.embedding(x_text)\n",
    "        x_text = self.relu(x_text)\n",
    "        x_text = x_text.mean(axis = 1)\n",
    "        x_text = self.fc(x_text)\n",
    "\n",
    "        # engineered features pipeline:\n",
    "        x_eng = self.eng_pipeline(x_eng)\n",
    "\n",
    "        # then, combine them with: \n",
    "        x_comb = torch.cat([x_text, x_eng], dim = 1).to(device)\n",
    "        \n",
    "        # pass x_comb through a couple more fully-connected layers and return output\n",
    "        return self.combine(x_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd9cef",
   "metadata": {},
   "source": [
    "The main ideas from the other pipelines remain. We first train separately following similar procedures to above, then we concatenate the features and pass them through several more fully-connected layers. Notably changes come in our text pipeline where we removed a fully connected layer and our dropout. These changes were a result of trail and error testing. Additionally, we bring our separate pipelines together before they are compressed back into our four-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a0f95593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "CombinedNet                              --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Linear: 2-1                       414\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Linear: 2-3                       228\n",
       "│    └─ReLU: 2-4                         --\n",
       "│    └─Linear: 2-5                       104\n",
       "├─Embedding: 1-2                         976,736\n",
       "├─ReLU: 1-3                              --\n",
       "├─Linear: 1-4                            264\n",
       "├─Sequential: 1-5                        --\n",
       "│    └─Linear: 2-6                       204\n",
       "│    └─ReLU: 2-7                         --\n",
       "│    └─Linear: 2-8                       104\n",
       "│    └─ReLU: 2-9                         --\n",
       "│    └─Linear: 2-10                      36\n",
       "=================================================================\n",
       "Total params: 978,090\n",
       "Trainable params: 978,090\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model = CombinedNet(vocab_size, embedding_dim, num_class, num_features).to(device)\n",
    "summary(combined_model, input_Size = (8, max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d752f13",
   "metadata": {},
   "source": [
    "Evidently, our model once again has a huge amount of trainable parameters. Lets see how they do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "06377472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | train accuracy    0.495 | time:  5.70s\n",
      "     test accuracy   0.5423128046078866\n",
      "| epoch   2 | train accuracy    0.564 | time:  5.37s\n",
      "     test accuracy   0.5560478511298184\n",
      "| epoch   3 | train accuracy    0.571 | time:  5.38s\n",
      "     test accuracy   0.5724412937527692\n",
      "| epoch   4 | train accuracy    0.584 | time:  5.38s\n",
      "     test accuracy   0.5799734160389898\n",
      "| epoch   5 | train accuracy    0.594 | time:  5.33s\n",
      "     test accuracy   0.5516171909614532\n",
      "| epoch   6 | train accuracy    0.611 | time:  5.45s\n",
      "     test accuracy   0.5990252547629596\n",
      "| epoch   7 | train accuracy    0.631 | time:  5.34s\n",
      "     test accuracy   0.6322552060256978\n",
      "| epoch   8 | train accuracy    0.644 | time:  5.38s\n",
      "     test accuracy   0.615861763402747\n",
      "| epoch   9 | train accuracy    0.654 | time:  5.48s\n",
      "     test accuracy   0.6473194505981391\n",
      "| epoch  10 | train accuracy    0.669 | time:  5.75s\n",
      "     test accuracy   0.6464333185644661\n",
      "| epoch  11 | train accuracy    0.677 | time:  6.30s\n",
      "     test accuracy   0.6566238369517058\n",
      "| epoch  12 | train accuracy    0.692 | time:  5.92s\n",
      "     test accuracy   0.6544085068675233\n",
      "| epoch  13 | train accuracy    0.699 | time:  6.66s\n",
      "     test accuracy   0.6575099689853788\n",
      "| epoch  14 | train accuracy    0.711 | time:  6.78s\n",
      "     test accuracy   0.6575099689853788\n",
      "| epoch  15 | train accuracy    0.720 | time:  7.07s\n",
      "     test accuracy   0.6326982720425344\n",
      "| epoch  16 | train accuracy    0.729 | time:  7.26s\n",
      "     test accuracy   0.66371289322109\n",
      "| epoch  17 | train accuracy    0.741 | time:  7.66s\n",
      "     test accuracy   0.6548515728843598\n",
      "| epoch  18 | train accuracy    0.748 | time: 10.54s\n",
      "     test accuracy   0.6526362428001772\n",
      "| epoch  19 | train accuracy    0.759 | time:  9.17s\n",
      "     test accuracy   0.6570669029685423\n",
      "| epoch  20 | train accuracy    0.765 | time:  8.58s\n",
      "     test accuracy   0.6641559592379265\n",
      "| epoch  21 | train accuracy    0.776 | time:  6.94s\n",
      "     test accuracy   0.6495347806823216\n",
      "| epoch  22 | train accuracy    0.784 | time:  6.50s\n",
      "     test accuracy   0.6486486486486487\n",
      "| epoch  23 | train accuracy    0.789 | time:  6.38s\n",
      "     test accuracy   0.66371289322109\n",
      "| epoch  24 | train accuracy    0.800 | time:  6.19s\n",
      "     test accuracy   0.6544085068675233\n",
      "| epoch  25 | train accuracy    0.811 | time:  6.24s\n",
      "     test accuracy   0.6260522817899867\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(combined_model, train_loader, \"both\")\n",
    "    print(\"     test accuracy  \", accuracy(combined_model, val_loader, \"both\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0b789e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6260522817899867"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(combined_model, val_loader, \"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba82028",
   "metadata": {},
   "source": [
    "After twenty-five epochs, we achieved an accuracy of **around 62%** which is slightly disappointing. If we look closely at the evolution of the our testing accuracy, we were steadily in the region of **around 65%** for a while. This drop may be a part of the training process or may be a reflection of the beginning of our *model overfitting* to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fd55933c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6839080459770115,\n",
       " 1: 0.4872448979591837,\n",
       " 2: 0.6977225672877847,\n",
       " 3: 0.7046568627450981}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_accuracy(combined_model, val_loader, mode=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b277a70d",
   "metadata": {},
   "source": [
    "Curse you Jazz! We are doing significant better on all the other genres apart from jazz. This may be because of jazz lyrics being slightly less theme driven combined with the atypical structure of jazz music. Maybe swing rhythms, tempo changes and odd time signatures don't fit neatly into any given category along with the lyrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c009a6b",
   "metadata": {},
   "source": [
    "# Closing Remarks\n",
    "Through our explorations, our metadata-only model yielded the highest accuracy around 65%, our combined network was not far behind with around 62% accuracy, and trailing begin was a purely lyric based approach that achieved 56% accuracy. Despite their varying and somewhat low accuracies, all the model outperformed the base rate of 36%. We narrowed down our search space to only four genres, hip hop, jazz, reggae, and rock. Of these genres, we had the easiest time distinguishing rock and reggae, with jazz proving especially hard to nail down.\n",
    "\n",
    "This blogpost was obviously an exercise in crafting deep learning pipelines through applying themes we learned in readings and class (i.e. mean-pooling, non-linear activation functions, hidden layers, etc.) and simple trial and error. One large takeaway I had was that feature concatenation does not necessarily guarantee improved model accuracy, and in some cases can provide more noise than clarity to the model. \n",
    "\n",
    "Some possible continuations for this project could be to modify model depth and complexity, implement vocabulary thresholds, expand the number of genres we look at, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910b328",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
